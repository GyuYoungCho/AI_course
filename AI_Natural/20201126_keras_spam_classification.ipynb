{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 사용 Text 분류 모델 구현\n",
    "\n",
    ": Keras의 Embedding,LSTM,Dropout 계층 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spam and ham 분류 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 5)\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... ham\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2 Unnamed: 2  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1    ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3    ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6    ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8   spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9   spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "10   ham  I'm gonna be home soon and i don't want to tal...        NaN   \n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po...        NaN   \n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...        NaN   \n",
       "13   ham  I've been searching for the right words to tha...        NaN   \n",
       "14   ham                I HAVE A DATE ON SUNDAY WITH WILL!!        NaN   \n",
       "15  spam  XXXMobileMovieClub: To use your credit, click ...        NaN   \n",
       "16   ham                         Oh k...i'm watching here:)        NaN   \n",
       "17   ham  Eh u remember how 2 spell his name... Yes i di...        NaN   \n",
       "18   ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...        NaN   \n",
       "19  spam  England v Macedonia - dont miss the goals/team...        NaN   \n",
       "\n",
       "   Unnamed: 3 Unnamed: 4  \n",
       "0         NaN        NaN  \n",
       "1         NaN        NaN  \n",
       "2         NaN        NaN  \n",
       "3         NaN        NaN  \n",
       "4         NaN        NaN  \n",
       "5         NaN        NaN  \n",
       "6         NaN        NaN  \n",
       "7         NaN        NaN  \n",
       "8         NaN        NaN  \n",
       "9         NaN        NaN  \n",
       "10        NaN        NaN  \n",
       "11        NaN        NaN  \n",
       "12        NaN        NaN  \n",
       "13        NaN        NaN  \n",
       "14        NaN        NaN  \n",
       "15        NaN        NaN  \n",
       "16        NaN        NaN  \n",
       "17        NaN        NaN  \n",
       "18        NaN        NaN  \n",
       "19        NaN        NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv',delimiter=',',encoding='latin-1')\n",
    "# ISO/IEC 8859-1, https://ko.wikipedia.org/wiki/ISO/IEC_8859-1\n",
    "print(df.shape)\n",
    "print(df['v2'][0], df['v1'][0])\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of ham and spam messages')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZgElEQVR4nO3de9RddX3n8fcHRC4KAhKYkIBBGmY1gKJEijoj4AXxCqXVwlKgljFdiCOOLRU6VrwMC7wxHbSiVJGgVRqvBAQRKXiZASHhYgxIiYKYBgl4AwS5hO/8sfezOIQnz9m5nCcnOe/XWmftvX9n73O+T9az8n1+91QVkiRNZJP1HYAkafiZLCRJfZksJEl9mSwkSX2ZLCRJfZksJEl9PWWQH57kduA+YAXwaFXNTrI98K/ADOB24I1V9Zv2/pOBY9v731FVl7bl+wLnAlsCFwMnVJ8xvzvssEPNmDFjnf9MkrQxW7hw4T1VNWXl8oEmi9ZBVXVPz/VJwOVVdXqSk9rrdyeZBRwB7AnsDHwnyR5VtQI4C5gDXE2TLA4BLpnoS2fMmMGCBQvW/U8jSRuxJD8fr3x9NEMdCsxtz+cCh/WUn19VD1XVbcASYL8kU4FtquqqtjZxXs8zkqRJMOhkUcC3kyxMMqct26mq7gRojzu25dOAX/Q8u7Qtm9aer1z+JEnmJFmQZMHdd9+9Dn8MSRptg26GenFVLUuyI3BZkp9McG/GKasJyp9cWHU2cDbA7NmzXcdEktaRgdYsqmpZe1wOfB3YD7irbVqiPS5vb18K7NLz+HRgWVs+fZxySdIkGViySPK0JFuPnQMHAz8G5gPHtLcdA1zQns8HjkiyeZLdgJnANW1T1X1J9k8S4OieZyRJk2CQzVA7AV9v/n/nKcAXq+pbSa4F5iU5FrgDeANAVS1OMg+4CXgUOL4dCQVwHI8Pnb2EPiOhJEnrVjbWJcpnz55dDp2VpNWTZGFVzV653BnckqS+TBaSpL4mYwb3BmnfE89b3yFoCC38yNHrOwRpvbBmIUnqy2QhSerLZCFJ6stkIUnqy2QhSerLZCFJ6stkIUnqa7WSRZJNkmwzqGAkScOpb7JI8sUk27Qrx94E3JLkxMGHJkkaFl1qFrOq6l6arUwvBnYFjhpkUJKk4dIlWWyWZDOaZHFBVT3CKnaqkyRtnLoki08DtwNPA76X5FnAvYMMSpI0XPouJFhVZwJn9hT9PMlBgwtJkjRsunRw75Tks0kuaa9n8fi2qJKkEdClGepc4FJg5/b634F3DigeSdIQ6pIsdqiqecBjAFX1KLBi4kckSRuTLsni90meSTsCKsn+wO8GGpUkaah02SnvXcB8YPck/xeYAvz5QKOSJA2VLqOhrktyAPCfgQC3tHMtJEkjom+ySHL4SkV7JPkdsKiqlg8mLEnSMOnSDHUs8ELgivb6QOBqmqTxgar6/IBikyQNiS7J4jHgj6vqLmjmXQBnAX8CfA8wWUjSRq7LaKgZY4mitRzYo6p+Ddh3IUkjoEvN4vtJLgK+3F7/Gc0aUU8DfjuowCRJw6NLsjieJkG8mGY01HnAV6uqANeIkqQR0GXobAFfaV+SpBHUZSHB/ZNcm+T+JA8nWZHEJcolaYR06eD+BHAkcCuwJfDfgI8PMihJ0nDp0mdBVS1JsmlVrQA+l+T/DTguSdIQ6ZIsHkjyVOCGJB8G7qTZNU+SNCK6NEMd1d73duD3wC40o6MkSSOib7Koqp9X1R+q6l6a7VXPraolXb8gyaZJrm/napBk+ySXJbm1PW7Xc+/JSZYkuSXJK3vK902yqH3vzCRZvR9TkrQ2uoyGujLJNkm2B26k6bM4YzW+4wTg5p7rk4DLq2omcHl7PbZd6xHAnsAhwCeTbNo+cxYwB5jZvg5Zje+XJK2lLs1Qz2hrFYcDn6uqfYGXd/nwJNOB1wCf6Sk+FJjbns8FDuspP7+qHqqq24AlwH5JpgLbVNVV7ZyP83qekSRNgi7J4intf9hvBC5azc//R+DvaLdkbe1UVXcCtMcd2/JpwC967lvalk1rz1cuf5Ikc5IsSLLg7rvvXs1QJUmr0iVZfAC4FFhSVdcmeTbNnIsJJXktsLyqFnaMZbx+iJqg/MmFVWdX1eyqmj1lypSOXytJ6qfLch9f5vFFBKmqn9FtNNSLgdcneTWwBbBNki8AdyWZWlV3tjWWsQ2UltKMtBozHVjWlk8fp1ySNEm6dHB/uO3g3izJ5UnuSfLmfs9V1clVNb2qZtB0XP9bVb2ZZj/vY9rbjgEuaM/nA0ck2TzJbjQd2de0TVX3tcuOBDi65xlJ0iTo0gx1cNvB/Vqav/L3AE5ci+88HXhFkluBV7TXVNViYB5wE/At4Ph2xjjAcTSd5EuAnwKXrMX3S5JWU5cZ3Ju1x1cDX6qqX6/uNIequhK4sj3/FfCyVdx3KnDqOOULgL1W60slSetMl2RxYZKfAA8Cb0syBfjDYMOSJA2TLjO4TwJeCMyuqkeAB2jmREiSRkSXDu6taHbLO6st2hmYPcigJEnDpUsH9+eAh4EXtddLgf81sIgkSUOnS7LYvao+DDwCUFUPMv5EOUnSRqpLsng4yZa0s6aT7A48NNCoJElDpctoqFNo5j3skuRfaGZm/+Ugg5IkDZcuy31cluQ6YH+a5qcTquqegUcmSRoaXZqhoFnldVPgqcBLkhw+uJAkScOmb80iyTnAc4DFPL7UeAFfG2BckqQh0qXPYv+qmjXwSCRJQ6tLM9RV7ZankqQR1aVmMZcmYfySZshsgKqq5ww0MknS0OiSLM4BjgIW8cTtUSVJI6JLsrijquYPPBJJ0tDqkix+kuSLwIX0zNyuKkdDSdKI6JIstqRJEgf3lDl0VpJGSJcZ3G+ZjEAkScOr6wxuSdIIM1lIkvoyWUiS+uqyNtS2wNHAjN77q+odA4tKkjRUuoyGuhi4GiflSdLI6pIstqiqdw08EknS0OrSZ/H5JG9NMjXJ9mOvgUcmSRoaXWoWDwMfAf4n7T7c7fHZgwpKkjRcuiSLdwF/5FaqkjS6ujRDLQYeGHQgkqTh1aVmsQK4IckVPHEhQYfOStKI6JIsvtG+JEkjqstCgnMnIxBJ0vDqMoN7JnAaMAvYYqy8qhwNJUkjoksH9+eAs4BHgYOA84DPDzIoSdJw6ZIstqyqy4FU1c+r6n3ASwcbliRpmHRJFn9Isglwa5K3J/lTYMd+DyXZIsk1SW5MsjjJ+9vy7ZNcluTW9rhdzzMnJ1mS5JYkr+wp3zfJova9M5NkDX5WSdIa6pIs3glsBbwD2Bc4Cjimw3MPAS+tqucC+wCHJNkfOAm4vKpmApe31ySZBRwB7AkcAnwyyabtZ50FzAFmtq9DOny/JGkd6TIa6lqAtnbxjqq6r8sHV1UB97eXm7WvAg4FDmzL5wJXAu9uy8+vqoeA25IsAfZLcjuwTVVd1cZxHnAYcEmXOCRJa69vzSLJ7CSLgB8Bi9pmpX27fHiSTZPcACwHLquqHwI7VdWdAO1xrElrGvCLnseXtmXT2vOVy8f7vjlJFiRZcPfdd3cJUZLUQZdmqHOAt1XVjKqaARxPM0Kqr6paUVX7ANNpagl7TXD7eP0QNUH5eN93dlXNrqrZU6ZM6RKiJKmDLsnivqr6/thFVf0A6NQU1fPMb2mamw4B7koyFaA9Lm9vWwrs0vPYdGBZWz59nHJJ0iTpkiyuSfLpJAcmOSDJJ4Erkzw/yfNX9VCSKe2WrCTZEng58BNgPo93kB8DXNCezweOSLJ5kt1oOrKvaZuq7kuyfzsK6uieZyRJk6DL2lD7tMdTVip/EU1z0KrmXEwF5rYjmjYB5lXVRUmuAuYlORa4A3gDQFUtTjIPuIlmAuDxVbWi/azjgHOBLWk6tu3clqRJ1GU01EFr8sFV9SPgeeOU/wp42SqeORU4dZzyBcBE/R2SpAHqMhrqhCTbpPGZJNclOXgygpMkDYcufRZ/VVX3AgfTDHN9C3D6QKOSJA2VLslibOjqq4HPVdWNjD+cVZK0keqSLBYm+TZNsrg0ydbAY4MNS5I0TLqMhjqWZkTUz6rqgSTPpGmKkiSNiC6joR4Druu5/hXwq0EGJUkaLl2aoSRJI85kIUnqa5XNUEm2n+jBqvr1ug9HkjSMJuqzWMjjq77uCvymPd+WZpmO3QYdnCRpOKyyGaqqdquqZwOXAq+rqh2q6pnAa4GvTVaAkqT1r0ufxQuq6uKxi6q6BDhgcCFJkoZNl3kW9yR5D/AFmmapN+PQWUkaKV1qFkcCU4CvA9+gWR/qyAHGJEkaMl0m5f0aOGESYpEkDam+ySLJHsDfAjN676+qVW16JEnayHTps/gy8CngM8CKPvdKkjZCXZLFo1V11sAjkSQNrS4d3BcmeVuSqUm2H3sNPDJJ0tDoUrM4pj2e2FNWwLPXfTiSpGHUZTSUy3pI0ojrUrMgyV7ALGCLsbKqOm9QQUmShkuXobOnAAfSJIuLgVcBPwBMFpI0Irp0cP858DLgl1X1FuC5wOYDjUqSNFS6JIsH261VH02yDbAcO7claaR06bNYkGRb4J9p9ri4H7hmkEFJkoZLl9FQb2tPP5XkW8A2VfWjwYYlSRomnUZDjamq2wcUhyRpiHXps5AkjTiThSSpr66T8rYDduGJS5RfN6igJEnDpcukvA8Cfwn8lGZNKNqj+1lI0ojoUrN4I7B7VT086GAkScOpS5/Fj4FtBxyHJGmIdUkWpwHXJ7k0yfyxV7+HkuyS5IokNydZnOSEtnz7JJclubU9btfzzMlJliS5Jckre8r3TbKofe/MJFmTH1aStGa6NEPNBT4ELAIeW43PfhT4m6q6LsnWwMIkl9H0f1xeVacnOQk4CXh3klnAEcCewM7Ad5LsUVUrgLOAOcDVNIsZHgJcshqxSJLWQpdkcU9Vnbm6H1xVdwJ3tuf3JbkZmAYcSrOKLTSJ6Erg3W35+VX1EHBbkiXAfklup5k1fhVAkvOAwzBZSNKk6ZIsFiY5DZgPPDRWuDpDZ5PMAJ4H/BDYqU0kVNWdSXZsb5tGU3MYs7Qte6Q9X7l8vO+ZQ1MDYdddd+0aniSpjy7J4nntcf+ess5DZ5M8Hfgq8M6quneC7obx3qgJyp9cWHU2cDbA7Nmzx71HkrT6uiwkeNCafniSzWgSxb9U1dfa4ruSTG1rFVNpljyHpsawS8/j04Flbfn0ccolSZOk6wzu19B0PPduq/qBPs8E+Cxwc1Wd0fPWfOAY4PT2eEFP+ReTnEHTwT0TuKaqViS5L8n+NM1YRwMf7xK3JGnd6DKD+1PAVsBBwGdods7rsp/Fi4GjgEVJbmjL/p4mScxLcixwB/AGgKpanGQecBPNSKrj25FQAMcB5wJb0nRs27ktSZOoS83iRVX1nCQ/qqr3J/kY8LV+D1XVDxi/vwGabVrHe+ZU4NRxyhcAe3WIVZI0AJ22VW2PDyTZmWZ00m6DC0mSNGy61CwuardV/QhwHc1IpM8MMihJ0nDpMhrqg+3pV5NcBGxRVb8bbFiSpGHSdTTUi4AZY/cnoarOG2BckqQh0mU01OeB3YEbgLHRSQWYLCRpRHSpWcwGZlWVM6IlaUR13c/iPw06EEnS8FplzSLJhTTNTVsDNyW5hicuJPj6wYcnSRoGEzVDfXTSopAkDbVVJouq+u5kBiJJGl5d+iwkSSPOZCFJ6muVySLJ5e3xQ5MXjiRpGE3UwT01yQHA65Ocz0oryK7OtqqSpA3bRMnivcBJNDvTnbHSe523VZUkbfgmGg31FeArSf6hZzFBSdII6rTqbJLXAy9pi66sqosGG5YkaZj0HQ2V5DTgBJrtTm8CTmjLJEkjostCgq8B9qmqxwCSzAWuB04eZGCSpOHRdZ7Ftj3nzxhAHJKkIdalZnEacH2SK2iGz74EaxWSNFK6dHB/KcmVwAtoksW7q+qXgw5MkjQ8Om2rWlV3AvMHHIskaUi5NpQkqS+ThSSprwmTRZJNkvx4soKRJA2nCZNFO7fixiS7TlI8kqQh1KWDeyqwuN2D+/djhe7BLUmjo0uyeP/Ao5AkDbUu8yy+m+RZwMyq+k6SrYBNBx+aJGlYdFlI8K3AV4BPt0XTgG8MMCZJ0pDpMnT2eODFwL0AVXUrsOMgg5IkDZcuyeKhqnp47CLJU2h2ypMkjYguyeK7Sf4e2DLJK4AvAxcONixJ0jDpkixOAu4GFgF/DVwMvKffQ0nOSbK8d1Jfku2TXJbk1va4Xc97JydZkuSWJK/sKd83yaL2vTOTZHV+QEnS2uubLNqJeXOBD9IMo51bVV2aoc4FDlmp7CTg8qqaCVzeXpNkFnAEsGf7zCeTjI24OguYA8xsXyt/piRpwLqMhnoN8FPgTOATwJIkr+r3XFV9D/j1SsWH0iQe2uNhPeXnV9VDVXUbsATYL8lUYJuquqpNUOf1PCNJmiRdJuV9DDioqpYAJNkd+CZwyRp8307tcudU1Z1JxkZVTQOu7rlvaVv2SHu+cvm4ksyhqYWw666uUCJJ60qXPovlY4mi9TNg+TqOY7x+iJqgfFxVdXZVza6q2VOmTFlnwUnSqFtlzSLJ4e3p4iQXA/No/qN+A3DtGn7fXUmmtrWKqTyedJYCu/TcNx1Y1pZPH6dckjSJJqpZvK59bQHcBRwAHEgzMmq7VT82ofnAMe35McAFPeVHJNk8yW40HdnXtE1W9yXZvx0FdXTPM5KkSbLKmkVVvWVtPjjJl2iSyw5JlgKnAKcD85IcC9xBU0uhqhYnmQfcBDwKHF9VK9qPOo5mZNWWNP0ka9JXIklaC307uNu/9P87MKP3/n5LlFfVkat462WruP9U4NRxyhcAe/WLU5I0OF1GQ30D+CzNrO3HBhqNJGkodUkWf6iqMwceiSRpaHVJFv8nySnAt4GHxgqr6rqBRSVJGipdksXewFHAS3m8Garaa0nSCOiSLP4UeHbvMuWSpNHSJVncCGzLup+1LWkN3fGBvdd3CBpCu7530cA+u0uy2An4SZJreWKfxYRDZyVJG48uyeKUgUchSRpqfZNFVX13MgKRJA2vLjO47+PxlV6fCmwG/L6qthlkYJKk4dGlZrF173WSw4D9BhWQJGn4dNnP4gmq6hs4x0KSRkqXZqjDey43AWYzwQZEkqSNT5fRUK/rOX8UuJ1mz2xJ0ojo0mexVvtaSJI2fBNtq/reCZ6rqvrgAOKRJA2hiWoWvx+n7GnAscAzAZOFJI2IibZV/djYeZKtgROAtwDnAx9b1XOSpI3PhH0WSbYH3gW8CZgLPL+qfjMZgUmShsdEfRYfAQ4Hzgb2rqr7Jy0qSdJQmWhS3t8AOwPvAZYlubd93Zfk3skJT5I0DCbqs1jt2d2SpI2TCUGS1JfJQpLUl8lCktSXyUKS1JfJQpLUl8lCktSXyUKS1JfJQpLUl8lCktSXyUKS1JfJQpLUl8lCktTXBpMskhyS5JYkS5KctL7jkaRRskEkiySbAv8EvAqYBRyZZNb6jUqSRscGkSyA/YAlVfWzqnqYZmvXQ9dzTJI0MibcVnWITAN+0XO9FPiTlW9KMgeY017en+SWSYhtFOwA3LO+gxgG+egx6zsEPZm/n2NOybr4lGeNV7ihJIvx/gXqSQVVZ9NsA6t1KMmCqpq9vuOQxuPv5+TYUJqhlgK79FxPB5atp1gkaeRsKMniWmBmkt2SPBU4Api/nmOSpJGxQTRDVdWjSd4OXApsCpxTVYvXc1ijxKY9DTN/PydBqp7U9C9J0hNsKM1QkqT1yGQhSerLZDHCksxI8uP1HYek4WeykCT1ZbLQpkn+OcniJN9OsmWStya5NsmNSb6aZCuAJOcmOSvJFUl+luSAJOckuTnJuev559BGIMnTknyz/d37cZK/SHJ7kg8luaZ9/VF77+uS/DDJ9Um+k2Sntvx9Sea2v8+3Jzk8yYeTLEryrSSbrd+fcsNkstBM4J+qak/gt8CfAV+rqhdU1XOBm4Fje+7fDngp8D+AC4H/DewJ7J1kn0mMWxunQ4BlVfXcqtoL+FZbfm9V7Qd8AvjHtuwHwP5V9Tya9eL+rudzdgdeQ7OG3BeAK6pqb+DBtlyryWSh26rqhvZ8ITAD2CvJ95MsAt5EkwzGXFjNeOtFwF1VtaiqHgMWt89Ka2MR8PK2JvFfq+p3bfmXeo4vbM+nA5e2v6cn8sTf00uq6pH28zbl8aSzCH9P14jJQg/1nK+gmah5LvD29i+x9wNbjHP/Yys9+xgbyCRPDa+q+ndgX5r/1E9L8t6xt3pva48fBz7R/p7+NeP8nrZ/yDxSj08o8/d0DZksNJ6tgTvbtt03re9gNDqS7Aw8UFVfAD4KPL996y96jle1588A/qM9dzngATPDajz/APwQ+DnNX3hbr99wNEL2Bj6S5DHgEeA44CvA5kl+SPMH7pHtve8DvpzkP4Crgd0mP9zR4XIfkoZaktuB2VXlnhXrkc1QkqS+rFlIkvqyZiFJ6stkIUnqy2QhSerLZCGtpST3r8a970vyt4P6fGlQTBaSpL5MFtIArGpF1NZzk/xbkluTvLXnmRPb1X5/lOT96yFsaZVMFtJgTLQi6nNoVj59IfDeJDsnOZhmBeD9gH2AfZO8ZHJDllbN5T6kwZgO/GuSqcBTgdt63rugqh4EHkxyBU2C+C/AwcD17T1Pp0ke35u8kKVVM1lIg/Fx4Iyqmp/kQJp1jMasPBO2gACnVdWnJyU6aTXZDCUNxkQroh6aZIskzwQOBK4FLgX+KsnTAZJMS7LjZAUr9WPNQlp7WyVZ2nN9BhOviHoN8E1gV+CDVbUMWJbkj4GrkgDcD7wZWD748KX+XBtKktSXzVCSpL5MFpKkvkwWkqS+TBaSpL5MFpKkvkwWkqS+TBaSpL7+P2jiJxFRRgm0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.v1)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of ham and spam messages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = df.v2, df.v1\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y. reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장을 토큰화 처리, 패딩, 데이터셋의 길이를 설정\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.preprocessing.text.Tokenizer(\n",
    "#     num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
    "#     split=' ', char_level=False, oov_token=None, document_count=0, **kwargs\n",
    "# )\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51, 387, 89, 372],\n",
       " [1, 16, 2, 101, 780, 37, 8, 161],\n",
       " [1,\n",
       "  187,\n",
       "  11,\n",
       "  2,\n",
       "  7,\n",
       "  1,\n",
       "  130,\n",
       "  2,\n",
       "  28,\n",
       "  13,\n",
       "  4,\n",
       "  296,\n",
       "  1,\n",
       "  106,\n",
       "  34,\n",
       "  3,\n",
       "  22,\n",
       "  537,\n",
       "  15,\n",
       "  28,\n",
       "  4,\n",
       "  20,\n",
       "  432,\n",
       "  167,\n",
       "  203,\n",
       "  113,\n",
       "  388,\n",
       "  9,\n",
       "  73,\n",
       "  10,\n",
       "  5],\n",
       " [462, 3, 409, 3, 22, 24, 410]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 1000# D, input_dim\n",
    "max_len = 150# T, sequence length : 한문장 길이, 데이터셋 길이\n",
    "\n",
    "tok = Tokenizer(num_words = max_words)\n",
    "\n",
    "tok.fit_on_texts(x_train)\n",
    "\n",
    "sequences = tok.texts_to_sequences(x_train)\n",
    "\n",
    "sequences[:4] # 길이가 서로 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 150)\n",
      "7379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 387,  89, 372],\n",
       "       [  0,   0,   0, ...,  37,   8, 161],\n",
       "       [  0,   0,   0, ...,  73,  10,   5],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0, 549,  12],\n",
       "       [  0,   0,   0, ...,  11, 654, 103],\n",
       "       [  0,   0,   0, ..., 240,  17,  20]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터 표현을 얻음\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len) # 신경망에 입력할 X값이다\n",
    "print(sequences_matrix.shape)  # (3900, 150), 2차원 행렬\n",
    "word_to_index = tok.word_index\n",
    "# print(word_to_index)\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "print(vocab_size)\n",
    "\n",
    "sequences_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "# tf.keras.layers.Embedding(\n",
    "#     input_dim, output_dim, embeddings_initializer='uniform',\n",
    "#     embeddings_regularizer=None, activity_regularizer=None,\n",
    "#     embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs\n",
    "# )\n",
    "\n",
    "# input_dim : input_dim   , D  , max_words : 1000\n",
    "# output_dim : hidden_size , H , 50\n",
    "# input_length : sequence_length , T : max_len:150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 150, 32)           10624     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 70,033\n",
      "Trainable params: 70,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words,50,input_length=max_len),\n",
    "    tf.keras.layers.LSTM(32, return_sequences = True),\n",
    "    tf.keras.layers.LSTM(32), #(?,150,50) , W : (50,32) --> (?,150,32)\n",
    "    tf.keras.layers.Dense(32,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1,activation='relu'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "# RMSProp : https://forensics.tistory.com/28\n",
    "# RMSprop 알고리즘은 Adadelta와 마찬가지로 Adagrad에서 학습률이 급격하게 감소하는 문제를 해결 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 0.5489 - accuracy: 0.8596 - val_loss: 0.1703 - val_accuracy: 0.8936\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.3135 - accuracy: 0.8990 - val_loss: 0.0634 - val_accuracy: 0.9821\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 97ms/step - loss: 0.1124 - accuracy: 0.9651 - val_loss: 0.0677 - val_accuracy: 0.9833\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.3117 - accuracy: 0.9558 - val_loss: 0.0452 - val_accuracy: 0.9897\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0695 - accuracy: 0.9827 - val_loss: 0.0644 - val_accuracy: 0.9833\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 99ms/step - loss: 0.0727 - accuracy: 0.9811 - val_loss: 0.0511 - val_accuracy: 0.9923\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.0834 - accuracy: 0.9869 - val_loss: 0.0500 - val_accuracy: 0.9936\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.0698 - accuracy: 0.9894 - val_loss: 0.0513 - val_accuracy: 0.9936\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0507 - accuracy: 0.9878 - val_loss: 0.0397 - val_accuracy: 0.9923\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0434 - accuracy: 0.9917 - val_loss: 0.0417 - val_accuracy: 0.9910\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 3s 101ms/step - loss: 0.0335 - accuracy: 0.9939 - val_loss: 0.0570 - val_accuracy: 0.9910\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 3s 100ms/step - loss: 0.0380 - accuracy: 0.9962 - val_loss: 0.0452 - val_accuracy: 0.9936\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0306 - accuracy: 0.9962 - val_loss: 0.1364 - val_accuracy: 0.9846\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 3s 104ms/step - loss: 0.0272 - accuracy: 0.9974 - val_loss: 0.0471 - val_accuracy: 0.9949\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0268 - accuracy: 0.9974 - val_loss: 0.0484 - val_accuracy: 0.9936\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0260 - accuracy: 0.9978 - val_loss: 0.0904 - val_accuracy: 0.9885\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 3s 102ms/step - loss: 0.0275 - accuracy: 0.9971 - val_loss: 0.1050 - val_accuracy: 0.9910\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.0252 - accuracy: 0.9981 - val_loss: 0.1043 - val_accuracy: 0.9910\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 3s 107ms/step - loss: 0.0268 - accuracy: 0.9978 - val_loss: 0.0683 - val_accuracy: 0.9936\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 3s 114ms/step - loss: 0.0261 - accuracy: 0.9978 - val_loss: 0.1065 - val_accuracy: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x161c57df668>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,y_train,batch_size=128, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1672, 150) (1672, 1)\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.2462 - accuracy: 0.9803\n",
      "Test set\n",
      "  Loss: 0.246\n",
      "  Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "#  Test 데이터셋의 벡터를 구함\n",
    "\n",
    "# 문자열을 정수 인덱스의 리스트로 변환\n",
    "test_sequences = tok.texts_to_sequences(x_test) \n",
    "\n",
    "# 벡터 표현을 얻음\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=max_len)  # 신경망에 입력할 X값이다\n",
    "print(test_sequences_matrix.shape,y_test.shape)  # (1672, 150), 2차원 행렬\n",
    "\n",
    "accr = model.evaluate(test_sequences_matrix,y_test)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.]], dtype=float32), array([0]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "preds = model.predict(test_sequences_matrix[17].reshape(1,-1)) # test_sequences_matrix[1]은 1차원이므로\n",
    "preds,y_test[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  64, 185, 565,  17,  10, 334])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.]], dtype=float32), array([0]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test_sequences_matrix[17].reshape(1,-1)) \n",
    "preds,y_test[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    3,    6,   18,   27,   37,   51,   54,   63,   69,   78,\n",
       "         83,  102,  110,  119,  128,  161,  168,  181,  185,  186,  190,\n",
       "        197,  199,  200,  202,  218,  222,  225,  235,  244,  247,  253,\n",
       "        261,  271,  272,  282,  287,  297,  312,  315,  320,  328,  341,\n",
       "        348,  353,  354,  357,  367,  368,  369,  378,  380,  383,  399,\n",
       "        419,  433,  442,  444,  448,  453,  458,  464,  466,  468,  469,\n",
       "        470,  476,  489,  490,  504,  507,  521,  525,  535,  537,  538,\n",
       "        540,  558,  559,  572,  573,  574,  581,  594,  596,  598,  608,\n",
       "        609,  614,  619,  633,  648,  651,  652,  664,  668,  670,  672,\n",
       "        677,  683,  707,  709,  716,  717,  724,  744,  749,  750,  753,\n",
       "        761,  768,  770,  777,  779,  781,  788,  791,  801,  809,  819,\n",
       "        830,  831,  832,  833,  836,  850,  854,  863,  871,  878,  880,\n",
       "        886,  894,  902,  912,  917,  920,  937,  940,  944,  947,  966,\n",
       "        986,  991,  992,  996, 1009, 1011, 1014, 1021, 1026, 1037, 1045,\n",
       "       1062, 1066, 1075, 1103, 1104, 1116, 1119, 1122, 1126, 1145, 1148,\n",
       "       1158, 1160, 1162, 1166, 1167, 1181, 1219, 1223, 1241, 1247, 1254,\n",
       "       1256, 1262, 1264, 1275, 1278, 1289, 1291, 1295, 1310, 1313, 1325,\n",
       "       1332, 1347, 1370, 1384, 1391, 1397, 1411, 1418, 1422, 1426, 1427,\n",
       "       1429, 1451, 1453, 1456, 1468, 1476, 1481, 1491, 1507, 1511, 1515,\n",
       "       1516, 1531, 1536, 1573, 1574, 1590, 1596, 1599, 1623, 1627, 1636,\n",
       "       1644, 1655, 1656, 1657, 1670], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = np.where(y_test==1)  # 답이 1인 인덱스\n",
    "ones[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.689795]] [1]\n",
      "[[12.83233]] [1]\n",
      "[[18.66509]] [1]\n",
      "[[18.433777]] [1]\n",
      "[[23.030798]] [1]\n",
      "[[4.8276997]] [1]\n",
      "[[28.857456]] [1]\n",
      "[[19.956835]] [1]\n",
      "[[17.089634]] [1]\n",
      "[[1.186591]] [1]\n",
      "[[0.]] [1]\n",
      "[[23.785772]] [1]\n",
      "[[13.117003]] [1]\n",
      "[[12.83233]] [1]\n",
      "[[20.863008]] [1]\n",
      "[[19.349165]] [1]\n",
      "[[21.83246]] [1]\n",
      "[[17.84381]] [1]\n",
      "[[30.993961]] [1]\n",
      "[[11.969296]] [1]\n",
      "[[25.915394]] [1]\n",
      "[[7.9383235]] [1]\n",
      "[[0.]] [1]\n",
      "[[17.84381]] [1]\n",
      "[[23.255264]] [1]\n",
      "[[22.663427]] [1]\n",
      "[[1.1629089]] [1]\n",
      "[[7.459043]] [1]\n",
      "[[0.9042627]] [1]\n",
      "[[9.41424]] [1]\n",
      "[[11.483192]] [1]\n",
      "[[29.401243]] [1]\n",
      "[[2.0030577]] [1]\n",
      "[[24.010464]] [1]\n",
      "[[5.037296]] [1]\n",
      "[[6.789721]] [1]\n",
      "[[24.072382]] [1]\n",
      "[[27.157368]] [1]\n",
      "[[25.450148]] [1]\n",
      "[[24.524105]] [1]\n",
      "[[29.019838]] [1]\n",
      "[[20.75768]] [1]\n",
      "[[0.76593065]] [1]\n",
      "[[15.172561]] [1]\n",
      "[[26.978584]] [1]\n",
      "[[0.]] [1]\n",
      "[[0.28005216]] [1]\n",
      "[[0.]] [1]\n",
      "[[19.35975]] [1]\n",
      "[[0.]] [1]\n",
      "[[18.700119]] [1]\n",
      "[[3.4563901]] [1]\n",
      "[[0.90723467]] [1]\n",
      "[[6.3556376]] [1]\n",
      "[[25.689005]] [1]\n",
      "[[20.062826]] [1]\n",
      "[[22.720428]] [1]\n",
      "[[21.648981]] [1]\n",
      "[[13.891847]] [1]\n",
      "[[25.49468]] [1]\n",
      "[[25.288662]] [1]\n",
      "[[16.527473]] [1]\n",
      "[[25.534615]] [1]\n",
      "[[15.397183]] [1]\n",
      "[[16.674322]] [1]\n",
      "[[19.279871]] [1]\n",
      "[[21.009043]] [1]\n",
      "[[2.5158231]] [1]\n",
      "[[25.74472]] [1]\n",
      "[[0.]] [1]\n",
      "[[4.0716195]] [1]\n",
      "[[28.580772]] [1]\n",
      "[[11.017991]] [1]\n",
      "[[5.255189]] [1]\n",
      "[[24.87233]] [1]\n",
      "[[23.836481]] [1]\n",
      "[[17.293627]] [1]\n",
      "[[3.4563901]] [1]\n",
      "[[27.67516]] [1]\n",
      "[[12.015313]] [1]\n",
      "[[12.713593]] [1]\n",
      "[[4.6424093]] [1]\n",
      "[[17.089634]] [1]\n",
      "[[25.318668]] [1]\n",
      "[[30.82562]] [1]\n",
      "[[16.104813]] [1]\n",
      "[[22.769596]] [1]\n",
      "[[13.439895]] [1]\n",
      "[[23.415224]] [1]\n",
      "[[26.881199]] [1]\n",
      "[[24.010464]] [1]\n",
      "[[28.339926]] [1]\n",
      "[[5.037296]] [1]\n",
      "[[0.]] [1]\n",
      "[[27.00702]] [1]\n",
      "[[13.504546]] [1]\n",
      "[[18.565536]] [1]\n",
      "[[15.523834]] [1]\n",
      "[[2.0030577]] [1]\n",
      "[[0.]] [1]\n",
      "[[0.]] [1]\n",
      "[[24.255033]] [1]\n",
      "[[19.234613]] [1]\n",
      "[[34.26282]] [1]\n",
      "[[18.47489]] [1]\n",
      "[[16.317743]] [1]\n",
      "[[17.942389]] [1]\n",
      "[[25.216904]] [1]\n",
      "[[27.821419]] [1]\n",
      "[[25.930376]] [1]\n",
      "[[29.433653]] [1]\n",
      "[[22.0515]] [1]\n",
      "[[0.]] [1]\n",
      "[[2.185262]] [1]\n",
      "[[31.218935]] [1]\n",
      "[[15.564773]] [1]\n",
      "[[4.1107216]] [1]\n",
      "[[24.017097]] [1]\n",
      "[[29.853804]] [1]\n",
      "[[17.23597]] [1]\n",
      "[[22.887568]] [1]\n",
      "[[27.920687]] [1]\n",
      "[[6.425407]] [1]\n",
      "[[13.030244]] [1]\n",
      "[[17.40916]] [1]\n",
      "[[32.302734]] [1]\n",
      "[[12.015313]] [1]\n",
      "[[20.023941]] [1]\n",
      "[[12.596538]] [1]\n",
      "[[20.956411]] [1]\n",
      "[[22.859877]] [1]\n",
      "[[4.6967034]] [1]\n",
      "[[0.]] [1]\n",
      "[[23.205166]] [1]\n",
      "[[28.580772]] [1]\n",
      "[[4.2053566]] [1]\n",
      "[[32.294395]] [1]\n",
      "[[0.]] [1]\n",
      "[[22.4547]] [1]\n",
      "[[19.902536]] [1]\n",
      "[[21.164759]] [1]\n",
      "[[6.6937394]] [1]\n",
      "[[17.84381]] [1]\n",
      "[[19.234613]] [1]\n",
      "[[22.808325]] [1]\n",
      "[[19.557798]] [1]\n",
      "[[11.254008]] [1]\n",
      "[[27.821507]] [1]\n",
      "[[14.913917]] [1]\n",
      "[[29.727478]] [1]\n",
      "[[25.3457]] [1]\n",
      "[[20.274496]] [1]\n",
      "[[1.9162861]] [1]\n",
      "[[2.2935193]] [1]\n",
      "[[21.895338]] [1]\n",
      "[[22.311674]] [1]\n",
      "[[22.663427]] [1]\n",
      "[[6.7119756]] [1]\n",
      "[[28.093185]] [1]\n",
      "[[5.037296]] [1]\n",
      "[[25.347443]] [1]\n",
      "[[4.2093062]] [1]\n",
      "[[26.45995]] [1]\n",
      "[[17.981684]] [1]\n",
      "[[22.720428]] [1]\n",
      "[[3.9102333]] [1]\n",
      "[[24.095335]] [1]\n",
      "[[6.084578]] [1]\n",
      "[[18.621656]] [1]\n",
      "[[27.288399]] [1]\n",
      "[[26.997263]] [1]\n",
      "[[23.126755]] [1]\n",
      "[[12.938839]] [1]\n",
      "[[7.8570504]] [1]\n",
      "[[2.2639174]] [1]\n",
      "[[16.317743]] [1]\n",
      "[[31.74626]] [1]\n",
      "[[20.50934]] [1]\n",
      "[[5.255189]] [1]\n",
      "[[29.347635]] [1]\n",
      "[[13.530067]] [1]\n",
      "[[28.093185]] [1]\n",
      "[[19.951681]] [1]\n",
      "[[22.043215]] [1]\n",
      "[[19.557798]] [1]\n",
      "[[33.337]] [1]\n",
      "[[4.475005]] [1]\n",
      "[[16.363287]] [1]\n",
      "[[19.280518]] [1]\n",
      "[[22.197744]] [1]\n",
      "[[7.062101]] [1]\n",
      "[[25.974571]] [1]\n",
      "[[0.09306374]] [1]\n",
      "[[12.83233]] [1]\n",
      "[[9.539071]] [1]\n",
      "[[23.944736]] [1]\n",
      "[[24.315168]] [1]\n",
      "[[0.24592805]] [1]\n",
      "[[22.951097]] [1]\n",
      "[[26.104883]] [1]\n",
      "[[30.82562]] [1]\n",
      "[[3.4563901]] [1]\n",
      "[[31.79871]] [1]\n",
      "[[31.408062]] [1]\n",
      "[[20.474289]] [1]\n",
      "[[10.6229925]] [1]\n",
      "[[5.7258925]] [1]\n",
      "[[1.0022427]] [1]\n",
      "[[29.956774]] [1]\n",
      "[[0.]] [1]\n",
      "[[29.372686]] [1]\n",
      "[[12.648417]] [1]\n",
      "[[15.384292]] [1]\n",
      "[[13.56231]] [1]\n",
      "[[26.45995]] [1]\n",
      "[[20.720524]] [1]\n",
      "[[2.8770432]] [1]\n",
      "[[25.53307]] [1]\n",
      "[[24.234535]] [1]\n",
      "[[5.037296]] [1]\n",
      "[[23.284924]] [1]\n",
      "[[17.4405]] [1]\n",
      "[[24.87233]] [1]\n",
      "[[34.26282]] [1]\n",
      "[[21.19892]] [1]\n"
     ]
    }
   ],
   "source": [
    "for one in ones[0]:\n",
    "    preds = model.predict(test_sequences_matrix[one].reshape(1,-1))\n",
    "    print(preds,y_test[one])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
